import os
import re
import datetime

# --- è¨­å®š ---
TARGET_FILENAME = "index.md"     # æ¢ã™ãƒ•ã‚¡ã‚¤ãƒ«å
OUTPUT_FILENAME = "CATALOG.md"   # å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å
IGNORE_DIRS = {".git", ".vscode", "files", "images", "scraps"} # ç„¡è¦–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã”ã¨ã®ã‚¢ã‚¤ã‚³ãƒ³å®šç¾©
STATUS_ICONS = {
    "stable": "ğŸŸ¢",
    "draft": "ğŸŸ¡",
    "deprecated": "ğŸ”´",
    "archived": "ğŸ”’",
    "wip": "ğŸš§"
}

def clean_text(text):
    """Markdownã®è£…é£¾ã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã¥ã‘ã‚‹"""
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text) # Boldé™¤å»
    text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text) # Linké™¤å»
    return text.strip()

def extract_description(content):
    """
    å„ªå…ˆé †ä½ã‚’ã¤ã‘ã¦æ¦‚è¦ã‚’æŠ½å‡ºã™ã‚‹
    1. Frontmatterã® description
    2. '## Definition' ç›´ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆ (Category Indexç”¨)
    3. '**ç›®çš„**' ã‚„ '**æ¦‚è¦**' (Context) (Project Indexç”¨)
    """
    
    # Strategy 1: '## Definition' (ä¸»ã«ã‚«ãƒ†ã‚´ãƒªãƒˆãƒƒãƒ—ç”¨)
    # ## Definition ã®æ¬¡ã®è¡Œã‹ã‚‰ã€æ¬¡ã®è¦‹å‡ºã—(#)ãŒæ¥ã‚‹ã¾ã§ã®é–“ã®æ–‡å­—åˆ—ã‚’å–å¾—
    def_match = re.search(r'^##\s+Definition\s*\n(.*?)(?=\n#|\Z)', content, re.DOTALL | re.MULTILINE)
    if def_match:
        desc = def_match.group(1).strip()
        # ç©ºè¡Œã‚„ç®‡æ¡æ›¸ãã‚’é©å½“ã«å‡¦ç†
        return clean_text(desc.split('\n')[0]) # æœ€åˆã®1è¡Œã ã‘è¿”ã™

    # Strategy 2: '**ç›®çš„**' or '**æ¦‚è¦**' or '**Goal**' (ç®‡æ¡æ›¸ãå¯¾å¿œ)
    # è¡Œé ­ã® * ã‚„ - ã‚’ç„¡è¦–ã—ã¦æŠ½å‡º
    ctx_match = re.search(r'[\*\-]\s*\*\*(?:ç›®çš„|æ¦‚è¦|Goal)\*\*\s*[:ï¼š]\s*(.*)', content)
    if ctx_match:
        return clean_text(ctx_match.group(1))

    return "No description"

def parse_md_file(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # 1. Frontmatter
    meta = {"tags": [], "status": "", "date": ""}
    fm_match = re.search(r'^---\n(.*?)\n---', content, re.DOTALL)
    
    if fm_match:
        fm_text = fm_match.group(1)
        tags_match = re.search(r'tags:\s*\[(.*?)\]', fm_text)
        if tags_match:
            meta["tags"] = [t.strip() for t in tags_match.group(1).split(',')]
        
        status_match = re.search(r'status:\s*(\w+)', fm_text)
        if status_match:
            meta["status"] = status_match.group(1).lower()

    # 2. Title
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    title = title_match.group(1).strip() if title_match else "No Title"

    # 3. Description (æ”¹å–„ç‰ˆ)
    summary = extract_description(content)
    
    return {
        "title": title,
        "path": filepath,
        "meta": meta,
        "summary": summary
    }

def generate_catalog():
    catalog_data = {} 

    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰èµ°æŸ»
    root_dir = "."
    for dirpath, dirnames, filenames in os.walk(root_dir):
        # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]
        
        if TARGET_FILENAME in filenames:
            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®index.mdã¯ã‚«ã‚¿ãƒ­ã‚°è‡ªä½“(README)ãªã®ã§é™¤å¤–
            if dirpath == ".":
                continue

            full_path = os.path.join(dirpath, TARGET_FILENAME)
            
            # ãƒ‘ã‚¹åˆ†è§£ (ä¾‹: 10_Network / Squid / index.md)
            # normpathã§OSã”ã¨ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’æ­£è¦åŒ–ã—ã€split
            rel_path = os.path.relpath(dirpath, ".")
            parts = rel_path.split(os.sep)

            # ã‚«ãƒ†ã‚´ãƒªæ±ºå®šãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£
            # ç¬¬1éšå±¤ (10_Network) ã‚’å¸¸ã«ã‚«ãƒ†ã‚´ãƒªåã¨ã™ã‚‹
            category = parts[0]
            
            # "10_Network/index.md" è‡ªä½“ã¯ã€ãã®ã‚«ãƒ†ã‚´ãƒªã®ç›®æ¬¡ãƒ•ã‚¡ã‚¤ãƒ«ãªã®ã§
            # CATALOG.md ã®ãƒªã‚¹ãƒˆã«ã¯ã€Œå«ã‚ãªã„ã€æ–¹é‡ã«ã™ã‚‹ (é‡è¤‡æ’é™¤)
            # ã‚‚ã—å«ã‚ãŸã„å ´åˆã¯ã€ã“ã® if æ–‡ã‚’å‰Šé™¤ã—ã¦ãã ã•ã„
            if len(parts) == 1 and TARGET_FILENAME in filenames:
                continue 

            data = parse_md_file(full_path)

            if category not in catalog_data:
                catalog_data[category] = []
            catalog_data[category].append(data)

    # Markdownç”Ÿæˆ
    lines = []
    lines.append("# ğŸ“š Document Catalog")
    lines.append(f"\nLast Updated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
    lines.append("> ã“ã®ãƒªã‚¹ãƒˆã¯ `generate_catalog.py` ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n")

    for category in sorted(catalog_data.keys()):
        lines.append(f"## {category}\n")
        
        # ã‚«ãƒ†ã‚´ãƒªå†…ã«ã‚¢ã‚¤ãƒ†ãƒ ãŒãªã„å ´åˆ (ãƒ«ãƒ¼ãƒˆindexã‚’é™¤å¤–ã—ãŸçµæœãªã©)
        if not catalog_data[category]:
             lines.append(f"*See [{category}](./{category}/{TARGET_FILENAME}) for details.*\n")
             continue

        lines.append("| Status | Document | Tags | Description |")
        lines.append("| :---: | :--- | :--- | :--- |")
        
        for item in sorted(catalog_data[category], key=lambda x: x['title']):
            stat_str = item['meta']['status']
            icon = STATUS_ICONS.get(stat_str, "âšª")
            
            # Windowsãƒ‘ã‚¹å¯¾ç­–ã®ç½®æ›
            link_path = item['path'].replace("\\", "/")
            link = f"[{item['title']}]({link_path})"
            
            tags_str = " ".join([f"`{t}`" for t in item['meta']['tags']])
            
            lines.append(f"| {icon} {stat_str} | {link} | {tags_str} | {item['summary']} |")
        
        lines.append("\n")

    with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    
    print(f"âœ… Generated {OUTPUT_FILENAME} successfully!")

if __name__ == "__main__":
    generate_catalog()
